<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Sapient - CCTV Analysis AI</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/grayscale.min.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="index.html">SAPIENT</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fas fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="requirements.html">Requirements</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="research.html">Research</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="hci.html">HCI</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="prototype.html">Prototype</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead">
      <div class="container d-flex h-100 align-items-center">
        <div class="mx-auto text-center">
          <h1 class="mx-auto my-0 text-uppercase">Prototype</h1>
          <h2 class="text-white-50 mx-auto mt-2 mb-5">.</h2>
          <a href="#about" class="btn btn-primary js-scroll-trigger">Show me more</a>
        </div>
      </div>
    </header>

    <!-- Black Spot Beneath Header Section -->
    <section id="about" class="about-section text-center">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h1 class="text-white mb-4 text-uppercase"></h1>
            <p class="text-white-50" style="text-align: justify;"></p>
          </div>
        </div>
      </div>
    </section>
    
    <!-- Review Existing Section -->
    <section id="project-background" class="projects-section bg-light">
      <div class="container">
        <div class="col-lg-12 text-center">
          <h1 class="section-heading text-uppercase">System architecture diagram</h1>
          <p class="line"></p>
          <p class="text-black-100" style="text-align: justify;" >We have two separate systems to present our prototype at the moment:</p>


          <center>
            <img class="sketch" src="img/ImageRecognitionArchitecture.png">
            <br><br>
            <img class="sketch" src="img/Azure_Infrastructure.png">
          </center>

          <br>
          <ul>
            <li><h3 align="left"><u>Image Recognition Architecture (Shun)</u></h3></li>
            <br>
            <li><h3 align="left"><u>Azure Cloud</u></h3>
                <ul>
                  <br>
                  <li><h4 align="left">Azure:</h4>
                    <p class="text-black-100" style="text-align: justify;" >
                      A public cloud provider which allows us to use their services such as renting their virtual machine, storage, networking and etc.</p>
                  </li>
                  <br>
                  <li><h4 align="left">VM:</h4>
                    <p class="text-black-100" style="text-align: justify;" >
                      It is a GPU virtual machine service powered by Azure, we use it to do image processing and hosting web application.</p>
                  </li>
                  <br>
                  <li><h4 align="left">Block Blob:</h4>
                    <p class="text-black-100" style="text-align: justify;" >
                      It is a cloud storage service provided by Azure, and this is for storing media objects files such as: images and videos. It can also be communicated by its own URL.</p>
                  </li>
                  <br>
                  <li><h4 align="left">Samples:</h4>
                    <p class="text-black-100" style="text-align: justify;" >
                      It is a folder consists of images and videos for Posture Recognition to analyse and test.</p>
                  </li>
                  <br>
                  <li><h4 align="left">Trainers:</h4>
                    <p class="text-black-100" style="text-align: justify;" >
                      It is a folder consists of images to train the classifier in the Posture Recognition.</p>
                  </li>
                  <br>
                  <li><h4 align="left">Dataset:</h4>
                    <p class="text-black-100" style="text-align: justify;" >
                      One of the components in Posture Recognition. It is a csv file has the data of x and y coordinates of standing, sitting and laying which has been transformed by using TensorFlow and Openpose to analyse the images in Trainers folder.</p>
                  </li>
                  <br>
                  <li><h4 align="left">Model:</h4>
                    <p class="text-black-100" style="text-align: justify;" >
                      One of the components in Posture Recognition. It is a pkl file generated by the classifier which processes the dataset, and then the Posture Recognition will use this model to process the sample images and videos</p>
                  </li>
                  <br>
                  <li><h4 align="left">Webapp:</h4>
                    <p class="text-black-100" style="text-align: justify;" >
                      It is a website written in HTML, CSS and JS, it is only used for displaying the sample image or video which has been processed by Posture Recognition for testing purpose.</p>
                  </li>
                </ul>
            </li>
            <br>
          </ul>




        </div>
      </div>
    </section>


    <!-- Summary of final Section -->
    <section id="requirements-gathering" class="projects-section bg-light">
      <br>
      <br>
      <br>
      <div class="container">
        <div class="col-lg-12 text-center">
          <h1 class="section-heading text-uppercase">Implementation of finished functionalities</h1>
          <p class="line"></p>
          <p class="text-black-100" style="text-align: justify;" >Overview (Shun)</p>
          <br>
          <br>
          <br>

          <div class="row"> 
            <div class="column">
              <h3 align="left"><u>ZONE TWO</u></h3>
              <img class="sketch" src="img/image-api.JPG" align="right" style="width:40%;">
              <br>
              <p class="text-black-100" style="text-align:justify;">
                  Firstly, we used openpose to analyse the images to extract x and y coordinates of 18 body joints from human. Using tensorflow to extract the data of standing, sitting and laying according to the patterns of 18 body joints. After that, it outputs a dataset which consists of records of the postures (sitting, standing and laying) with 18 body joints.
                  <br><br>
                  Secondly, we feed the datasets into MLPclassifiers/Adaboost in order to train them. After that, it outputs a model which is equivalent to a brain with the knowledge of the behaviour of sitting, standing and laying.
                  <br><br>
                  Finally, we used openpose again with the model generated to process and analyse if the input file has human who is performing sitting, standing and laying. The input file can be a JPG image, pre-saved video and live video (camera).
                  <br><br>
                  One thing that require to notice is the number of the images that we first used to train the classifiers have to be more than 10, otherwise, both MLPclassifier and Adaboost will have insufficient number of data to compare. 
                  <br><br>
              </p>

              <h3 align="right"><u>ZONE ONE (Shun)</u></h3>
              <img class="sketch" src="img/sketches/xxx.png" align="left">
              <p class="text-black-100" style="text-align:justify;">The same procedure of installing and configuring the API will be performed by Shun Shao 
                who is in charge of face and object recognition. Shun is also using his own machine to install and configure the APIs with the specs.
              <br>
              <br>
              The detail about the face recognition installation.
              Here are the dependencies required for face recognition:
              <br>   
                <br>- software one
                <br>- software two
              <br>
              The detail about the object recognition installation.
              Here are the dependencies required for object recognition:
              <br>
                <br>- software one
                <br>- software two
              </p>
              <br>

              <h3 align="left"><u>DASHBOARD (Shun)</u></h3>
              <img class="sketch" src="img/sketches/xxx.png" align="right">
              <p class="text-black-100" style="text-align:justify;">bla bla bla</p>

              <h3 align="right"><u>CLOUD BASED INFRASTRUCTURE</u></h3>
              <img class="sketch" src="img/Azure_Infrastructure.png" align="left">
              <p class="text-black-100" style="text-align:justify;">We rented a standard GPU family Azure machine with NC6 series of graphic card which sufficient for openpose and tensorflow to process image and extract data. And then, we hosted the Posture Recognition and a webapp for testing purpose into the server for the purpose of testing deployment for one recognition. 
              <br>
              <br>
              Firstly, we installed the apache HTTP server and test if the web application is functional by clicking the url of the virtual machine. Secondly, we installed the environment for the posture recognition that we developed and test if posture recognition functions properly and outputs the processed image or video by using the webapp to check. In other words, we are treating this kind of webapp as the screen of the server.
              <br>
              <br>
              Lastly, we used another Azure service called Azure Storage --Block Blob to store the media files which are classified into two folders: one consisting of lots of images to train the posture recognition's classifiers and the other consisting of sample images and videos to let the Posture Recognition to identify the sitting, standing and laying features. The virtual machine then can use HTTP channel to extract the media files to pass to the Posture Recognition.
              </p>
              <br>








            </div>
          </div>
        </div>
      </div>

    </section>


    </section>

    <!-- Footer -->
    <footer class="bg-black small text-center text-white-50">
      <div class="container">
        Copyright &copy; Sapient Platform 2018
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/grayscale.min.js"></script>

  </body>

</html>
