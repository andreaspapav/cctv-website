<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Sapient - CCTV Analysis AI</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/grayscale.min.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="index.html">SAPIENT</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fas fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="requirements.html">Requirements</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="research.html">Research</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="hci.html">HCI</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="prototype.html">Prototype</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead">
      <div class="container d-flex h-100 align-items-center">
        <div class="mx-auto text-center">
          <h1 class="mx-auto my-0 text-uppercase">Prototype</h1>
          <h2 class="text-white-50 mx-auto mt-2 mb-5">.</h2>
          <a href="#about" class="btn btn-primary js-scroll-trigger">Show me more</a>
        </div>
      </div>
    </header>

    <!-- Black Spot Beneath Header Section -->
    <section id="about" class="about-section text-center">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h1 class="text-white mb-4 text-uppercase"></h1>
            <p class="text-white-50" style="text-align: justify;"></p>
          </div>
        </div>
      </div>
    </section>
    
    <!-- Review Existing Section -->
    <section id="project-background" class="projects-section bg-light">
      <div class="container">
        <div class="col-lg-12 text-center">
          <h1 class="section-heading text-uppercase">System architecture diagram</h1>
          <p class="line"></p>
          <p class="text-black-100" style="text-align: justify;" >We have three separate systems to present our prototype:</p>


          <center>
            <img class="sketch" src="img/systemArchitecture.png">
          </center>

          <br>
          <ul>
            <li><h3 align="left">Azure VM:</h3> <p class="text-black-100" style="text-align: justify;">It is the virtual machine from Azure Cloud Platform which gathers APIs, video and webapplication all together in order to process them in one box.</p></li>
            <br>
            <li><h3 align="left">Video:</h3> <p class="text-black-100" style="text-align: justify;">It is a directory containing video as an input to the APIs.</p></li>
            <br>
            <li><h3 align="left">Item Recognition:</h3> <p class="text-black-100" style="text-align: justify;">It is an image recognition processing package divided into object, image and face recognition. The output will be the video after being processed by the package.</p></li>
            <br>
            <li><h3 align="left">Image Recognition:</h3> <p class="text-black-100" style="text-align: justify;">It is an API which can track points from human body from recorded video, and outputs the video with the tracking lines on human body.</p></li>
            <br>
            <li><h3 align="left">Face Recognition:</h3> <p class="text-black-100" style="text-align: justify;">It is an API which can track the face from human and display the name of this person in a live stream video.</p></li>
            <br>
            <li><h3 align="left">Webapp:</h3> <p class="text-black-100" style="text-align: justify;">It is the web application which displays the video which has been processed.</p></li>
          </ul>




        </div>
      </div>
    </section>


    <!-- Summary of final Section -->
    <section id="requirements-gathering" class="projects-section bg-light">
      <br>
      <br>
      <br>
      <div class="container">
        <div class="col-lg-12 text-center">
          <h1 class="section-heading text-uppercase">Implementation of finished functionalities</h1>
          <p class="line"></p>
          <p class="text-black-100" style="text-align: justify;" >Here is the procedure of how we managed to combine the APIs, Webapp and Azure VM together in the Azure cloud platform:</p>
          <br>
          <br>
          <br>

          <div class="row"> 
            <div class="column">
              <h3 align="left"><u>POSTURE RECOGNITION</u></h3>
              <img class="sketch" src="img/image-api.jpg" align="right" style="width:40%;">
              <br>
              <p class="text-black-100" style="text-align:justify;">
                  Firstly, we used openpose to analyse the images to extract x and y coordinates of 18 body joints from human. Using tensorflow to extract the data of standing, sitting and laying according to the patterns of 18 body joints. After that, it outputs a dataset which consists of records of the postures (sitting, standing and laying) with 18 body joints.
                  <br><br>
                  Secondly, we feed the datasets into MLPclassifiers/Adaboost in order to train them. After that, it outputs a model which is equivalent to a brain with the knowledge of the behaviour of sitting, standing and laying.
                  <br><br>
                  Finally, we used openpose again with the model generated to process and analyse if the input file has human who is performing sitting, standing and laying. The input file can be a JPG image, pre-saved video and live video (camera).
                  <br><br>
              </p>

              <h3><u>FACE & OBJECT RECOGNITION</u></h3>
              <img class="sketch" src="img/sketches/xxx.png" align="left">
              <p class="text-black-100" style="text-align:justify;">The same procedure of installing and configuring the API will be performed by Shun Shao 
                who is in charge of face and object recognition. Shun is also using his own machine to install and configure the APIs with the specs.
              <br>
              <br>
              The detail about the face recognition installation.
              Here are the dependencies required for face recognition:
              <br>   
                <br>- software one
                <br>- software two
              <br>
              The detail about the object recognition installation.
              Here are the dependencies required for object recognition:
              <br>
                <br>- software one
                <br>- software two
              </p>
              <br>

              <h3 align="left"><u>USER INTERFACE</u></h3>
              <img class="sketch" src="img/sketches/xxx.png" align="right">
              <p class="text-black-100" style="text-align:justify;">According to the client requirement, they have no requirement for having a user interface for using this CCTV AI application. So we implemented a very simple web application just to display the video which has been processed by the APIs for testing if our web application is functional.
              <br>
              <br>
              The web application is written in HTML, CSS and Bootstrap.css. It is non-responsive and designed for 1280 X 720 resolution screen since this is the typical screen will be used in the CCTV monitoring centre. The web application will display the processed video located in the output directory from the APIs.
              </p>

              <h3 align="right"><u>CLOUD BASED INFRASTRUCTURE</u></h3>
              <img class="sketch" src="img/sketches/xxx.png" align="left">
              <p class="text-black-100" style="text-align:justify;">After gathering all the components of the web application, we will rent a ubuntu virtual machine in Azure and put all the APIs and the web application in it. Since this is an image rendering focused project, we rent a GPU optimized virtual machine with Standard NC6 powered by the Nvidia Tesla K80 which is enough for developing our image recognition project.
              <br>
              <br>
              Firstly, we installed the apache HTTP server and pulled the web application from the github, and test if the web application is functional by clicking the url of the virtual machine. Secondly, we installed the APIs and follow the installation instruction generated from Andreas and Shun who are responsible for the API development. Finally, after the directory configuration of both the APIs and the web application, when you click on the url of the virtual machine you should be able to see the video which has been processed by the APIs.
              </p>
              <br>








            </div>
          </div>
        </div>
      </div>

    </section>


    </section>

    <!-- Footer -->
    <footer class="bg-black small text-center text-white-50">
      <div class="container">
        Copyright &copy; Sapient Platform 2018
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/grayscale.min.js"></script>

  </body>

</html>
