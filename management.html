<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Sapient - CCTV Analysis AI</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/grayscale.min.css" rel="stylesheet">
    <link href="css/custom.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="index.html">SAPIENT</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fas fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="requirements.html">Requirements</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="research.html">Research</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="hci.html">HCI</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="design.html">Design</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="testing.html">Testing</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="evaluation.html">Evaluation</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="management.html">Management</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead">
      <div class="container d-flex h-100 align-items-center">
        <div class="mx-auto text-center">
          <h1 class="mx-auto my-0 text-uppercase">Management</h1>
          <h2 class="text-white-50 mx-auto mt-2 mb-5">Legal issues, users and deployment documentation</h2>
          <a href="#about" class="btn btn-primary js-scroll-trigger">Show me more</a>
        </div>
      </div>
    </header>

    <!-- Black Spot Beneath Header Section -->
    <section id="about" class="about-section text-center">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h1 class="text-white mb-4 text-uppercase"></h1>
            <p class="text-white-50" style="text-align: justify;"></p>
          </div>
        </div>
      </div>
    </section>

    <div class="container-fluid bg-light">
      <div class="row">
        <!--Sidebar menu-->
        <div class="col-sm-2">
          <br>
          <br>
          <div id="sidebar" class="sidebar">
           <nav class="navbar navbar-shrink">
              <ul class="navbar-nav">
                <li class="nav-item">
                  <a class="nav-link js-scroll-trigger" href="#legal_issues">Legal Issues</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link js-scroll-trigger" href="#user_manual">User Manual</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link js-scroll-trigger" href="#deployment_manual">Deployment Manual</a>
                </li>
                <li class="nav-item">
                  <a class="nav-link js-scroll-trigger" href="#gant_chart">Gant Chart</a>
                </li>
              </ul>
            </nav>
          </div>
        </div>


    <div class="col-sm-10">

    <section id="legal_issues" class="projects-section bg-light">
      <div class="container">
        <div class="col-lg-12 text-center">
          <h1 class="section-heading text-uppercase">Legal Issues</h1>
          <p class="line"></p>
          <h2 align="center"><u>Consideration of potential liability</u></h2></br>
            <p class="text-black-100" style="text-align: justify;" >Our project is about CCTV AI recognition, according to the scenarios and user cases,
               I find there are three aspects of liability we have to take into account.</br></br>

              Once the software has been placed into real public scenes, it will replace the human supervisor to a certain extent. It cannot behave as good
              as human, and it leads to lack of accuracy. The criminal may happen without any alert brought by the software, as the result, the police may
              not able to stop the criminals or secure the scenes. The reasons for the uncertainty can the software itself and hacker attacks, the development
              team cannot guarantee any kinds of public use, it is only a beta version without strict and long-run testing.</br></br>

              The other aspect of liability is about the privacy. There will be a big legal concern to place the AI CCTV into the public, as required by the
              privacy law, the Camden Council (client) has to put clear notifications in that area, like ‘this area is under CCTV supervisor and enforced by AI reading
              technology’. Otherwise, the software is not allowed to use and the violation of privacy will cause
              huge penalties.</br></br>

              The final thing is about the privacy of the people in library images which has been used to understand the human tensors of standing,
              sitting or lying. We only use these images to understand human pose and delete the images immediately. The sources of the images are form
              different websites, they are open and free to use as declared in the websites themselves.</br>
              </p>

              <h2 align="center"><u>Intellectual Property</u></h2></br>
              <h3 align="left">a)	Regarding our project</h3>
                <p class="text-black-100" style="text-align: justify;" >This project will be used under an open source software license, the reason to choose GNU GPL
                  as our license is that it offers the best solution in legal area for both the client and the development team.</br></br>

                  GNU GPL stands for GNU Affero General Public License version 3. Copyright © 2007 Free Software Foundation, Inc. <https://fsf.org/> There are three main intellectual property rights have been taken into account when choosing the right license, they are copyrights, trademarks and patent. The contributor owns the copyright as declared in the license, ‘A "contributor" is a copyright holder who authorizes use under this license of the Program or a work on which the Program is based.’(GNU).
                  There is no special trademark for the project, like symbol or project name, but the code should be used with declaration at the top of the page about the source of the software, like ‘This code was first developed by UCL CS Team28, and the link is …’. The GNU license protect the contributors’ patent right, and it is worldwide, also royalty-free, the development team is allowed to use, distribute, or sell it which is clearly declared in the ‘essential patent claims’.</br></br>

                  Any people can copy, modify and distribute the software as the license offers, so the client can deliver his requirements to other development team build on the software in the future, even charge on it. ‘This License explicitly affirms your unlimited permission to run the unmodified Program.’ (GNU) it not only maximizes the clients’ profit but also encourages other teams to build on it, make it to be a better product to the public. However, it protects the contributors’ IPRs at the meanwhile, since it needs to be agreed on the license of the project. There is no warranty of any kinds of potential use of the project, it is declared in the section 15 in the GNU GPL, the development team does not have liabilities of any kinds of improper use of the software, also the team does not guarantee the reliability of the software, it is always a beta version other than a mature product through strict testing.
                </p>

                <h3 align="left">b)	Regarding last team files</h3>
                <p class="text-black-100" style="text-align: justify;" >The project is building on the last team’s work called tf-pose-estimation and CamdenPlatform, we agree all
                  the terms declared in the Apache License Version 2.0, January 2004 and GNU Affero General Public License version 3. As required, we will put the source of the
                  previous team and contact of our team onto the website and top of the source code.</br></br>

                <h3 align="left">c)	Intellectual Property for all the APIs and SDKs</h3>
                <p class="text-black-100" style="text-align: justify;" >There is a quite long list of license agreements for the third-party environment, APIs, SDKs.
                  After read through the licenses, we agreed all of the terms declared in the licenses, they are ‘1.Python PSF LICENSE AGREEMENT 2. OpenCV 3-clause BSD License
                  3. © 2015, Anaconda, Inc. All rights reserved under the 3-clause BSD License 4. W3C DOCUMENT LICENSE for HTML5 5. Google Cloud Platform License Agreement for
                  Google Cloud Vision API 6. Openpose: multiperson Keypoint detection software license agreement 7. Tensorflow & tfopenpose : Apache License Version 2.0,
                  January 2004 8.</p>

                <h2 align="center"><u>Data Privacy</u></h2></br>
                <p class="text-black-100" style="text-align: justify;" >We choose the OSS type of licenses (GNU GPL), so the source code is open to public to review and edit.
                  In this section, I will extent and explain the GDPR - General Data Protection Regulation in depth. The first thing is about personal data, as discussed in
                  the section 1 of this article, we are using the human images from tons of websites for machine learning, it may cause violation of privacy. Therefore,
                  we double checked the source is free and carefully delete all the images once finish the processing, just keep the ‘pose data’ of the human which is
                  legally allowed. It ensures we are using the data properly and not kept longer than necessary. We guarantee that the personal data is be used accurate and
                  adequate. Another aspect of GDPR is ‘Data Protection by Design and Default’, the contributor owns the copyright and patent as declared in the license,
                  the use of the previous team’s work is restricted by the license respectively which are agreed by the client and development team. When changes made onto
                  the source code by other teams or individuals, the client and development team just ensure the current adapting one is safe and unchanged. When a potential
                  breach is uncovered, the client must stop the use and find the solution and prevent further violation or lost.</p>

                <h3 align="left">Image Samples</h3>
                <p class="text-black-100" style="text-align: justify;" >As we mentioned in other pages, we need to have images sample in order to train our posture and face recognition. We shall claim that we did not use the images from online without permission. The sample images we collected are from opensource photos library called '123RF' and ourselves. Ever since we finish training the image recognition, we delete the photos because they have no use after that. Therefore, this should be legal and if anyone has arguement with using the photos with himself inside the photo, he should argue with the company with opensource photos library which has the photos of him.</p>
        </div>
      </div>
    </section>

    <section id="user_manual" class="projects-section bg-light">
      <div class="container">
        <div class="col-lg-12 text-center">
          <h1 class="section-heading text-uppercase">User Manual</h1>
          <p class="line"></p>
          <h2 class="section-heading text-uppercase"><u>Instructions</u></h2>
          <br>
          <p class="text-black-100" style="text-align: justify;" >The purpose of this webapp is just showing how the Image Recognition AI analyse the image, video and live video. Due to lack of the SSL certification on our webapp, please use <b>FireFox</b> to browse our webapp in order to experience the full functionality.</p>
          <br>
          <div class="row">
            <div class="column">
              <p class="text-black-100" style="text-align: justify;" >Firstly, when you hover on the three different recognitions, it gives you brief description of what each of them does. Let's click the power button to process the next page.</p>
            </div>
            <div class="column">
              <img class="sketch" src="img/management/homepage.png" align="right" style="width: 100%;">
            </div>
          </div>
          <br>
          <div class="row">
            <div class="column">
              <p class="text-black-100" style="text-align: justify;" >Secondly, this menu page allows you to choose one of the input type to perform the Image Recognition. When you click on the image icon, there are two options: uploading an image and webcam. Although there is a live video icon on the webpage, it is not yet functional, it can only be processed in another webapp we built from local webserver.</p>
            </div>
            <div class="column">
              <img class="sketch" src="img/management/menu.png" align="right" style="width: 100%;">
            </div>
          </div>
          <br>
          <div class="row">
            <div class="column">
              <p class="text-black-100" style="text-align: justify;" >The instruction for this uploading image page is very simple, first you choose the file that you want the machine to analyse and hit upload. You will then see there is an image you uploaded from the left field. After that, press the 'analyse' button and wait for the AI to process the data until there is a text output to be appeared from the terminal on the right. To be aware that you can only upload 'jpg' file.</p>
            </div>
            <div class="column">
              <img class="sketch" src="img/management/image_upload.png" align="right" style="width: 100%;">
            </div>
          </div>
          <br>
          <div class="row">
            <div class="column">
              <p class="text-black-100" style="text-align: justify;" >For the image webcam page, you first have to allow the webpage to access your webcam, if you don't see this option jumped out from your web browser, please change it to using <b>FireFox</b>. After that, press 'screenshot' to take the image and if you don't like the image you took, press 'reset' to take another one. Finally, pressing 'analyse' button will perform the same feature as the uploading image page.</p>
            </div>
            <div class="column">
              <img class="sketch" src="img/management/image_webcam.png" align="right" style="width: 100%;">
            </div>
          </div>
          <br>
          <div class="row">
            <div class="column">
              <p class="text-black-100" style="text-align: justify;" >This video webpage is slightly different from other webpages, you first have to choose the file in mp4, and it is better to be something less than 10 seconds in order to process it quickly. Hit 'upload' and then press 'analyse' and wait for the processing. Finally, the output text from Posture Recognition will be displayed on the terminal on the right and the analysed video from Face and Item Recognition will displayed in the middle of the webpage.</p>
            </div>
            <div class="column">
              <img class="sketch" src="img/management/video.png" align="right" style="width: 100%;">
            </div>
          </div>
          <br>
          <br>
          <h2 class="section-heading text-uppercase"><u>Webapp Links</u></h2>
          <br>
          <p class="text-black-100" style="text-align: justify;" >Due to the high cost of the AzureVM, we are not able to continuously running our application online. If you would like to visit the webapp, please contact <i>zcabsaz@ucl.ac.uk</i> and provide the timeslot which you wish to use our webapp.
            <br>
            <br>
          For the live-streaming webapp hosted in local, you will have to contact <i>shun.shao.17@ucl.ac.uk</i>.
          </p>
        </div>
      </div>
    </section>


    <section id="deployment_manual" class="projects-section bg-light">
      <div class="container">
        <div class="col-lg-12 text-center">
          <h1 class="section-heading text-uppercase">Deployment Manual</h1>
          <p class="line"></p>
          <br>
          <h2 class="section-heading text-uppercase"><u>AzureVM Integration</u></h2>
          <br>
          <p class="text-black-100" style="text-align: justify;" >This session has 4 sections to deploy:</p>
          <ul class="text-black-100" style="text-align: justify;">
            <li>AzureVM</li>
            <li>Linux Server Configuration</li>
            <li>Posture Recognition Installation</li>
            <li>Face/Item Recognition Installation</li>
          </ul>
          <br>
          <h2 align="left">AzureVM</h2>
          <p class="text-black-100" style="text-align: justify;">Login to the Azure Dashboard, and deploy a ubuntu virtual machine. In details, please make sure the following:</p>
          <ul class="text-black-100" style="text-align: justify;">
            <li>open the port for ssh, http and https</li>
            <li>GPU family virtual machine</li>
            <li>Attaching an additional block storage disk to the VM</li>
          </ul>
          <br>
          <h2 align="left">Linux Server Configuration</h2>
          <p class="text-black-100" style="text-align: justify;">After you start running the Ubuntu virtual machine, make sure you first refresh the apt-get repository, and then install the followings:</p>
          <ul class="text-black-100" style="text-align: justify;">
            <li>php</li>
            <li>Anaconda</li>
            <li>swig</li>
            <li>apache2</li>
            <li>essential-tools</li>
            <li>ffmpeg</li>
          </ul>
          <p class="text-black-100" style="text-align: justify;">After the installation, perform the followings:</p>
          <ul class="text-black-100" style="text-align: justify;">
            <li>git clone out 'sapient' repository</li>
            <li>setting the default directory of the apache to be '/var/www/sapient/Web'</li>
            <li>sudo chown www-data:www-data /var/www/</li>
            <li>sudo chmod 755 -R /var/www/</li>
            <li>adding your current user to www-data group</li>
          </ul>
          <br>
          <h2 align="left">Posture Recognition</h2>
          <p class="text-black-100" style="text-align: justify;">The following is the installation guide:</p>
          <ul class="text-black-100" style="text-align: justify;">
            <li>conda create -n posture python=3.6 pip</li>
            <li>source activate posture</li>
            <li>pip install -r requirements.txt (inside the tf-pose-estimation directory)</li>
            <li>pip install tensorflow</li>
            <li>pip install opencv-python pandas sklearn numpy</li>
            <li>cd tf_pose/pafprocess</li>
            <li>swig -python -c++ pafprocess.i && python setup.py build_ext --inplace</li>
          </ul>
          <br>
          <h2 align="left">Face & Item Recognition</h2>
          <p class="text-black-100" style="text-align: justify;">The following is the installation guide:</p>
          <ul class="text-black-100" style="text-align: justify;">
            <li>source activate posture</li>
            <li>pip install -r requirements.txt</li>
            <li>pip install google-cloud-vision</li>
            <li>export GOOGLE_APPLICATION_CREDENTIALS="/var/www/sapient/FaceItem/service-account-file.json"</li>
          </ul>
          <br>
          <h2 align="left">Additional</h2>
          <p class="text-black-100" style="text-align: justify;">If you find any further installation issue, please contact <i>Shiko Azuma</i></p>
        </div>
      </div>
    </section>


    <section id="gant_chart" class="projects-section bg-light">
      <div class="container">
        <div class="col-lg-12 text-center">
          <h1 class="section-heading text-uppercase">Gant Chart</h1>
          <p class="line"></p>
          <img src="img/GanttChart.png" class="gant_chart">
          <img src="img/ganttchart_table.png" class="ganttchart_table">
        </div>
      </div>
    </section>

</div>
</div>
</div>
    <!-- Footer -->
    <footer class="bg-black small text-center text-white-50">
      <div class="container">
        Copyright &copy; Sapient Platform 2018
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/grayscale.min.js"></script>
    <script src="js/sidebar.js"></script>

  </body>

</html>
